{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the KMeans Inferrer\n",
    "\n",
    "The inferenza KMeans model is desigend to mimic the basic predict method from SciKit Learn's [`KMeans` model class](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "To use the KMeans Inferrer follow these steps:\n",
    "1. pretrain your Kmeans model using the `Kmeans` class from Scikit Learn\n",
    "2. convert your model into ONNX format and save to an `.onnx` file\n",
    "3. In your Rust project, load your model from the `.onnx` file and call the `predict` method to make predictions\n",
    "\n",
    "## Step 1 - pretrain a KMeans model\n",
    "Here we will use a very simple KMeans model as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X, y, centers = make_blobs(n_samples=50, n_features=3, centers=5, cluster_std=0.5, shuffle=True, random_state=42,  return_centers=True)\n",
    "num_features = X.shape[1]\n",
    "num_clusters = centers.shape[0]\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters, init='k-means++', n_init=10, max_iter=500, tol=1e-04, random_state=42)\n",
    "km.fit(X)\n",
    "\n",
    "y_km = km.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - save the model to `.onnx` file type\n",
    "\n",
    "Here we use the `skl2onnx` package to convert our model into the `.onnx` file type so it can be injested by the inferenza KManes inferrer later on.\n",
    "\n",
    "**A quick note about `initial_type`:**\n",
    "\n",
    "Scikit-learn models are flexible in what they accept â€” for example, a KMeans model can take a NumPy array, a list of lists, or a DataFrame. However, ONNX is type-strict and needs to know the input signature of the model (i.e. the name, type and shape of the inputs you intend to use with this model later on).\n",
    "\n",
    "The `initial_types` argument takes a list of tuple, with each tuple describing one input for the model. In this example we are only inclduing one input, so there is one tuple.\n",
    "\n",
    "The first element in the tuple is the name of the input, here 'float_input'. This input name is only needed for the ONNX file structure but we do not call it internally during the inference process, meaning you can use any name you prefer.\n",
    "\n",
    "The second argument in the tuple defines the shape and data type of the input. Here we use the `FloatTensorType` class provided by `skl2onnx` with our number of features as an argument, this describes a 2D float tensor of shape (batch_size, num_features). At this point we don't know what our batch size might be so we set the value to `None` to give us flexibility later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('float_input', FloatTensorType(shape=[None, 3]))]\n"
     ]
    }
   ],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# Output filename for the exported ONNX model\n",
    "out_onnx = \"kmeans.onnx\"\n",
    "\n",
    "# In this example, we are creating a float32 input of any batch size with 3 features\n",
    "initial_type = [('float_input', FloatTensorType([None, num_features]))]\n",
    "\n",
    "# Convert the trained scikit-learn KMeans model (km) to an ONNX model\n",
    "onnx_model = convert_sklearn(km, initial_types=initial_type)\n",
    "\n",
    "# Add custom metadata to the ONNX model for identification\n",
    "meta =  onnx_model.metadata_props.add()\n",
    "meta.key = \"sklearn_model\"\n",
    "meta.value = \"KMeans\"\n",
    "\n",
    "# Save the serialized ONNX model to disk\n",
    "with open(out_onnx, \"wb\") as f:\n",
    "    f.write( onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Load your model and make predictions\n",
    "\n",
    "Now that we've created an `.onnx` file with our pre-trained model, we can initialise the inferenza `KmeansModel` class and generate some predictions with unseen inputs.\n",
    "\n",
    "```rust\n",
    "// create an inferenza KmeansModel from your onnx file\n",
    "let kmeans = KmeansModel::load_from_onnx_proto(\"<path_to_file>/kmeans.onnx\");\n",
    "\n",
    "// define your input as a 3x3 array (3 inputs with 3 features each)\n",
    "let input = Array2::from_shape_vec(\n",
    "    (3, 3), vec![\n",
    "        3.9755416, -9.76483, 9.557824, // this should be predicted as class 0\n",
    "        3.9755416, -9.76483, 9.557824, // this should be predicted as class 0\n",
    "        -2.466838, 9.029932, 4.4263315 // this should be predicted as class 1\n",
    "    ]\n",
    ").unwrap();\n",
    "\n",
    "// make predictions on our inputs with kmeans predict() function\n",
    "let prediction = kmeans.predict(\n",
    "    input\n",
    ");\n",
    "\n",
    "// print prediction result\n",
    "println!(\"{:?}\", prediction.to_vec());\n",
    "// output: [0, 0, 1]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison\n",
    "\n",
    "The goal of the inferenza project is to provide a rust based inferrer that performs inferences faster than traditional python-based approaches. See below a speed comparison for making the preictions on the 3 inputs from the above example with SciKit Learn's built in predict function compared to inferenza:\n",
    "\n",
    "**sklearn: 0.0012 seconds**  \n",
    "**inferenza: 0.000095 seconds (~12x faster than sklearn)**\n",
    "\n",
    "Test code for reference:\n",
    "\n",
    "Python timed example\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x_test = np.array([\n",
    "        [3.9755416, -9.76483, 9.557824],\n",
    "        [3.9755416, -9.76483, 9.557824],\n",
    "        [-2.466838, 9.029932, 4.4263315],\n",
    "    ])\n",
    "\n",
    "start = time.time()\n",
    "y_km = km.predict(x_test)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Elapsed time: {end - start:.4f} seconds\")\n",
    "```\n",
    "\n",
    "Rust timed example\n",
    "```rust\n",
    "let input = Array2::from_shape_vec(\n",
    "    (3, 3), vec![\n",
    "        3.9755416, -9.76483, 9.557824, // 0\n",
    "        3.9755416, -9.76483, 9.557824, // 0\n",
    "        -2.466838, 9.029932, 4.4263315 // 1\n",
    "    ]\n",
    ").unwrap();\n",
    "\n",
    "let start = Instant::now();\n",
    "let prediction = kmeans.predict(\n",
    "    input\n",
    ");\n",
    "let duration = start.elapsed();\n",
    "\n",
    "let seconds = duration.as_secs_f64();\n",
    "\n",
    "println!(\"Time elapsed: {:.6} seconds\", seconds);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inferenza",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
